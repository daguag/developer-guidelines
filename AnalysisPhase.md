# Analysis Phase

Based on your drafted plan (in the preceding phase) consider if there is a need of data collection, reconsider its necessity and alternate ways to fulfill purposes (for instance to identify the app) and think about which measures you have to integrate into the processing of data in which way.
You should also take into account

 - [ ] data collection: differentiate between data accessed from device and data generated by user -> done in previous phase primary and secondary

In order to follow the **Privacy by Design** principle [(see Introduction)](Introduction.md) collection and linkage of user data and the way data connections are established must be taken into consideration from the very beginning. For this we provide you some good practices.

 - [ ] add PbD description in intro and adjust the link

## Device-specific information is sensitive

It must be taken into account that **Device-specific information** is subject to a number of restrictions, since they are **sensitive**. This is a fact widely neglected, that's why we list the ones most commonly used:

 - Unique identifiers (UDID, IMEI, MAC addresses etc.) may only be obtained if necessary for the specific purpose and after an actively confirmed opt-in
 - Unique identifiers must not be used for individual user tracking
     - [ ] is there a legal restriction or should we forumlate this more weak?
 - Tracking IDs (IDFA, AAID) should be avoided and where necessary be transmitted in encrypted form
    - [ ] *(sollte eigentlich gar nicht drin sein, in irgendeiner Form wird es aber dennoch einfließen.)* -> ja gut, aber... was jetzt?
 - User-disabled tracking options must be respected 
     - [ ] *(das ist aber nur opt out, ist an anderer Stelle vielleicht schon erwähnt, also hier nochmal stärker machen - kann auch in anderer Form erwähnt werden, aber ist eben wichtig hier unseren Fokus zu schärfen)*

<br>

| Legal Hint: Personenbeziehbare Daten|
|---|
| todo |


Access to device-specific information (e.g. UDID, IMEI, MAC addresses, etc.) MUST be obtained from the user via an Opt-In and MAY only take place to the extent that is really required.
Many app manufacturers claim that device IDs are “anonymized” using hash values. As this is actually pseudonymization2 and not anonymization, the manufacturers are wrong here.  There is no reason why these IDs should be accessed to recognize users. 

It is another matter, however, with regard to the “Tracking-IDs“ created specifically by the operating system manufacturers (IDFA (Identifier for Advertisers, iOS); AAID (Android Advertising ID, Android)). These MUST be transmitted in encrypted form (see → 4.1.1 Encrypted communication and validation) and the Opt-In will also be obligatory in future. The different development levels of the data protection standards for mobile operating systems mean a standard evaluation is not possible.

With iOS (from version 6.0) it is possible to change the IDFA or refuse utilization of it for the most parts. The programmer is however responsible for respecting this refusal option.
The way the Android Advertising ID works in Android is similar to the way of the IDFA in iOS. It is generated completed dynamically by the user with a Google app that has been available since Android 4.0.x and can be reset at any time. It is mandatory to use for user identification as of August 1, 2014 when it comes to user tracking. It does also have an option for limiting usage.

There are also unique IDs that can be used for authentication or user identification issues. It is not possible to change the Android ID in Android, which is often used by apps for tracking purposes, without installing a Custom ROM3 or modifying the user’s rights using a Root4 software/tool. The same applies to the UDID on iOS devices, that can only be faked on a device with a Jailbreak5 installed. Use of these IDs is mostly prohibited by the operating systems manufacturer (especially for ad tracking purposes).

 - [] pasted from MTD


##Privacy Policy

The processing of personal data makes it necessary to define a **Privacy Policy**. Since the minimum requirements of the local data protection laws have to be fullfilled anyway we suggest to take data protection serious and go a step further to build attractive and competitive apps.

[comment]:"keine minimale Compliance, sondern ordentlicher Datenschutz"

*If we talk about personal data, keep in mind that **a lot of data can be linked to individuals**, especially in the field of mobile apps.
That's why it is advised to avoid the storage and processing of data where possible*

[comment]:"(Daten auf dem Gerät sind immer auch möglicherweise personalisierbar ... -> grundsätzlich immer möglich Daten für Rückschlüsse nutzbar? -> Datenminimierung)"

- [] Textbox: Legal Hint: Privacy Policy requirements

The definition of a privacy policy implies, but is not limited to:

### Which types of personal data are accessed and why?
 * How will this data be used?
 * How will this data be stored?
 * Which third-parties will receive access to the data and under what conditions?
 * Statement, that collected data will be protected from unauthorized access
 * Contact data of the actual Data Protection Officer
     * [ ] is this necessary for any app? / is it practicable for app developers?
 * Statement on how to access personal saved data as a user
 * Statement on how to initiate personal data deletion as a user
 * extended information about privacy policies etc. can be found here: [https://www.enisa.europa.eu/]
     - [ ] (hier einfach die basalen Punkte, (die zeitlos sind) übernehmen*
     - [ ] make clearer reference to concrete pages

### Is data leaving the main ecosystem?
Think about on which level your data is processed and transmitted.

  - definition the level of data leakage
    - is data leaving the "local boundary" 
    - is data leaving the "eco system boundary"
    - is data leaving the "3rd party boundary"
    - [ ] explain what that exactly means!

For the processing of data, you need a proper contract, that you are entitled to do so. This is bound to a number of duties

  - [ ] *(german ADV)* (translation of the term?)
 -  [ ] which duties exactly?
     - [ ] *(auch die Auftrragsdatenverarbeiter verpflichten auf Datenschutzprinzipien)*

### Which data needs which level of protection?

Special categories of data are placed under particular protection of the law.

  0. no personal reference: no protection necessary 

    - [ ] *(gibt es eigentlich nicht)* *(alterativ: Folgen der Ausnutzung? -> Keine Folgen)*

      ​	consequences on usage = no consequences, no abuse possible

  1. person related or relatable: protection necessary


     ​	consequences on usage = displeasing consequences, abuse possible

  2. sensitive data: processing not recommended

     ​	consequences on usage = unwanted consequences, can be used against individual

  3. dangerous data: processing prohibited

    -  [ ] *(was ist da genau gemeint, Gefahr für Leib und Leben? / streichen?)*

     ​	*consequences on usage = threat to life or freedom of individual*

     <br>

     ​|Legal Hint: "Data Protection Level"|
     |---|
     | Add legal hint on data protection levels|

<br>

| Legal Hint: "Data Economy"|
|---|
|Access to data (e.g. PIM, media, etc.) MUST take place in line with data economy1 according to §3a BDSG. Data MUST NOT be passed on to third parties without an Opt-In from the user. Utilization of the data SHOULD be explained to the user (why does the application need this access, and what will not function if I do not provide this access?).|

#### Sensitive Data

(REM: Ergänzungen vielleicht in eine Art Kasten)
Amongst these are personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership, and the processing of genetic data, biometric data for the purpose of uniquely identifying a natural person, data concerning health or data concerning a natural person's sex life or sexual orientation. These data generally may only be used where the data subject has given explicit consent regarding these very categories of information.

#### Extent of data used

Where the information on individuals used by the app is particularly comprehensive, exposing their conduct or characteristics, particular attention needs to be paid to the protection of those data.

  - Is data used that must be deletable on user demand? (@ULD: which data is affected)
*(grundsätzlich immer)*

      - a routine must be implemented to ensure full deletion of user data on demand
        - all saved data from the user must be deletable
        - this applies also to data stored in the cloud
        - if no such routine is implemented, the user is provided with contact data to send a deletion request

  - Special protection

    - are persons with special protection needs concerned? *(was dann @ULD? betroffene Schützenswert? Kinder etc.)*

(REM: Ergänzeungen vielleicht in einer art Kasten)
For instance if children or other persons who require particular legal protection are involved, the processing of data might be more restricted than otherwise.

- add Box: Further References...

## Risk Assessment

[comment]:"to be discussed"

 * [ ] which generic parts of RA can be put in Introduction.md / Foundations.md and which special part might be relevant for the specific phases

 * [ ] the criteria mentioned above are a good basis for the risk assessment, which shoule be revisited after every step in the development lifecycle

 * [ ] what means risk here for the developer? [comment]:"risk to endanger privacy of clients"


- all processed data needs to be analysed to specify a risk level of potential malicious use of the data
  - based on these risk levels special protection routines need to be applied *(hier auf standardisierte Risk-Level verweisen @ULD habt ihr da was?)*



**Examples:**

 - [ ] TODO...
